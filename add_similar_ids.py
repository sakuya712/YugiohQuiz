import json
import os
import glob
from difflib import SequenceMatcher

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®å®šç¾©
DATA_DIR = 'data'
# é¡ä¼¼åº¦ã®é–¾å€¤ã¨ä¸Šä½Nå€‹ã®å®šç¾©
SIMILARITY_THRESHOLD = 0.4  # é¡ä¼¼åº¦ãŒã“ã®å€¤ä»¥ä¸Šã®ã‚‚ã®ã ã‘ã‚’å¯¾è±¡ã¨ã™ã‚‹ (å¿…è¦ã«å¿œã˜ã¦èª¿æ•´)
TOP_N_SIMILAR = 10          # ä¸Šä½Nå€‹ã‚’ä¿å­˜ã™ã‚‹

def similarity(a, b):
    """åå‰ã®é¡ä¼¼åº¦ã‚’0ï½1ã§è¿”ã™"""
    return SequenceMatcher(None, a, b).ratio()

def add_similar_ids():
    """
    dataãƒ•ã‚©ãƒ«ãƒ€å†…ã®ã™ã¹ã¦ã®.jsonãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ä¼¼ã¦ã„ã‚‹ã‚«ãƒ¼ãƒ‰åã‚’è¨­å®šã—ã¾ã™
    """
    
    # 1. dataãƒ•ã‚©ãƒ«ãƒ€å†…ã®å…¨JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    # **.json æ‹¡å¼µå­ã‚’æŒã¤ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¯¾è±¡ã«ã—ã¾ã™
    search_pattern = os.path.join(DATA_DIR, "*.json")
    json_paths = glob.glob(search_pattern)
    
    if not json_paths:
        print(f"ã‚¨ãƒ©ãƒ¼: {DATA_DIR} ãƒ•ã‚©ãƒ«ãƒ€å†…ã« .json ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    # 2. å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ
    all_cards = {}
    
    # 3. æ¤œç´¢ã•ã‚ŒãŸJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€ã¤ãšã¤èª­ã¿ã“ã£ã‚€
    for json_path in json_paths:
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                card_id = data.get('card_id')
                name_jp = data.get('name_ruby')
                
                # 'card_id'ã¨'name_jp'ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
                if card_id and name_jp:
                    all_cards[card_id] = {'name': name_jp, 'path': json_path, 'data': data}
                else:
                    print(f"âš ï¸ è­¦å‘Š: {os.path.basename(json_path)} ã« 'card_id' ã¾ãŸã¯ 'name_jp' ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                
                
        except json.JSONDecodeError:
            print(f"âš ï¸ è­¦å‘Š: {os.path.basename(json_path)} ã®JSONå½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        except Exception as e:
            print(f"âš ï¸ è­¦å‘Š: {os.path.basename(json_path)} ã®å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")

    print(f"âœ… åˆè¨ˆ {len(all_cards)} ä»¶ã®ã‚«ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚é¡ä¼¼åº¦è¨ˆç®—ã‚’é–‹å§‹ã—ã¾ã™...")
    
    
    # 4. å…¨ã¦ã®ã‚«ãƒ¼ãƒ‰ã«å¯¾ã—ã¦é¡ä¼¼åº¦ã‚’è¨ˆç®—ã—ã€'similar_ids'ã‚’æ±ºå®š
    for target_id, target_card in all_cards.items():
        similarities = []
        target_name = target_card['name']
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ä»¥å¤–ã®ã™ã¹ã¦ã®ã‚«ãƒ¼ãƒ‰ã¨æ¯”è¼ƒ
        for other_id, other_card in all_cards.items():
            if target_id == other_id:
                continue # è‡ªåˆ†è‡ªèº«ã¯ã‚¹ã‚­ãƒƒãƒ—
            
            other_name = other_card['name']
            sim_ratio = similarity(target_name, other_name)
            
            # é–¾å€¤ä»¥ä¸Šã®é¡ä¼¼åº¦ã‚’æŒã¤ã‚‚ã®ã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ 
            if sim_ratio >= SIMILARITY_THRESHOLD:
                similarities.append((sim_ratio, other_id))
            
        # é¡ä¼¼åº¦ãŒé«˜ã„é †ã«ã‚½ãƒ¼ãƒˆã—ã€ä¸Šä½Nå€‹ï¼ˆè‡ªåˆ†è‡ªèº«ã‚’é™¤ãï¼‰ã‚’æŠ½å‡º
        # é¡ä¼¼åº¦ã¯é™é †ï¼ˆå¤§ãã„é †ï¼‰
        similarities.sort(key=lambda x: x[0], reverse=True)
            
        # ä¸Šä½Nå€‹ã®IDã‚’æŠ½å‡º
        top_similar_ids = [id for ratio, id in similarities[:TOP_N_SIMILAR]]
        
        # 5. å…ƒã®JSONãƒ‡ãƒ¼ã‚¿ã« 'similar_ids' ã‚’è¿½åŠ ãƒ»æ›´æ–°
        target_data = target_card['data']
        target_data['similar_ids'] = top_similar_ids 
            
        # 6. JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ãä¿å­˜
        try:
            with open(target_card['path'], 'w', encoding='utf-8') as f:
                # èª­ã¿ã‚„ã™ã„ã‚ˆã†ã«ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚’ã¤ã‘ã¦ä¿å­˜
                json.dump(target_data, f, ensure_ascii=False, indent=4)
            # print(f"âœ¨ {target_id}: 'similar_ids' ({len(top_similar_ids)}ä»¶) ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")

        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {os.path.basename(target_card['path'])} ã®æ›¸ãè¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            
    print("\nğŸ‰ å…¨ã¦ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®é¡ä¼¼ã‚«ãƒ¼ãƒ‰IDã®è¿½åŠ å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    add_similar_ids()